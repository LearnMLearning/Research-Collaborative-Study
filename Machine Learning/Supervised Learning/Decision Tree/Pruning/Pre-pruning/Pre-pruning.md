关于预剪枝（pre-pruning）的基本概念，在前面已经介绍过了，下面就直接举个例子来看看预剪枝（pre-pruning）是怎样操作的。数据集为（图片来自西瓜书）：
![[Pasted image 20240630144823.png]]
这个数据集根据信息增益可以构造出一颗未剪枝的决策树（图片来自西瓜书）：
![[Pasted image 20240630144936.png]]
因为**色泽**和**脐部**的信息增益值最大，所以从这两个中随机挑选一个，这里选择**脐部**来对数据集进行划分，这会产生三个分支，如下图所示：
![[Pasted image 20240630145040.png]]
但是因为是预剪枝，所以要判断是否应该进行这个划分，判断的标准**就是看划分前后的泛化性能是否有提升，也就是如果划分后泛化性能有提升，则划分；否则，不划分**。 下面来看看是否要用脐部进行划分，**划分前：所有样本都在根节点，把该结点标记为叶结点，其类别标记为训练集中样本数量最多的类别，因此标记为好瓜**，然后用验证集对其性能评估，可以看出样本{4，5，8}被正确分类，其他被错误分类，因此精度为43.9%。**划分后**： 划分后的的决策树为：
![[Pasted image 20240630145116.png]]
则验证集在这颗决策树上的精度为：5/7 = 71.4% > 42.9%。因此，用 **脐部** 进行划分。

接下来，决策树算法对结点 (2) 进行划分，再次使用信息增益挑选出值最大的那个特征，这里我就不算了，计算方法和上面类似，信息增益值最大的那个特征是“色泽”，则使用“色泽”划分后决策树为：

![[Pasted image 20240630145138.png]]
但到底该不该划分这个结点，还是要用验证集进行计算，可以看到划分后，精度为$4/7=0.571<0.714$，因此，预剪枝策略将禁止划分结点 (2) 。对于结点 (3) 最优的属性为“根蒂”，划分后验证集精度仍为 $71.4\%$，因此这个划分不能提升验证集精度，所以预剪枝将禁止结点 (3) 划分。对于结点 (4) ，其所含训练样本已属于同一类，所以不再进行划分。

所以基于预剪枝策略生成的最终的决策树为：
![[Pasted image 20240630145217.png]]
**总结**： 对比未剪枝的决策树和经过预剪枝的决策树可以看出：预剪枝使得决策树的很多分支都没有“展开”，这不仅降低了过拟合的风险，还显著减少了决策树的训练时间开销和测试时间开销。但是，另一方面，因为预剪枝是基于“贪心”的，所以，虽然当前划分不能提升泛化性能，但是基于该划分的后续划分却有可能导致性能提升，因此预剪枝决策树有可能带来**欠拟合**的风险。

