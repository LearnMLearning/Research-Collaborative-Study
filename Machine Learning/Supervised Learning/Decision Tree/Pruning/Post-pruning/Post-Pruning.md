后剪枝就是先构造一颗完整的决策树，然后自底向上的对非叶结点进行考察，若将该结点对应的子树换为叶结点能够带来泛化性能的提升，则把该子树替换为叶结点。前剪枝时已经说过了，使用前面给出的训练集会生成一颗（未剪枝）决策树：
![[Pasted image 20240630145728.png]]
后剪枝算法首先考察上图中的结点 (6)，若将以其为根节点的子树删除，即相当于把结点 (6) 替换为叶结点，替换后的叶结点包括编号为 $\{7,15\}$ 的训练样本，因此把该叶结点标记为“好瓜”（因为这里正负样本数量相等，所以随便标记一个类别），因此此时的决策树在验证集上的精度为 $57.1\%$（为剪枝的决策树为 $42.9\%$ ），所以后剪枝策略决定剪枝，剪枝后的决策树如下图所示：
![[Pasted image 20240630145823.png]]
接着考察结点 5，同样的操作，把以其为根节点的子树替换为叶结点，替换后的叶结点包含编号为$\{6,7,15\}$ 的训练样本，根据“多数原则”把该叶结点标记为“好瓜”，测试的决策树精度认仍为 $57.1\%$，所以不进行剪枝。

考察结点 2 ，和上述操作一样，不多说了，叶结点包含编号为 $\{1,2,3,14\}$ 的训练样本，标记为“好瓜”，此时决策树在验证集上的精度为 $71.4\%$，因此，后剪枝策略决定剪枝。剪枝后的决策树为：

![[Pasted image 20240630150044.png]]
 接着考察结点 3 ，同样的操作，剪枝后的决策树在验证集上的精度为 $71.4\%$，没有提升，因此不剪枝；对于结点 1 ，剪枝后的决策树的精度为 $42.9\%$，精度下降，因此也不剪枝。
 
因此，基于后剪枝策略生成的最终的决策树如上图所示，其在验证集上的精度为 $71.4\%$。

总结：对比预剪枝和后剪枝，能够发现，后剪枝决策树通常比预剪枝决策树保留了更多的分支，一般情形下，后剪枝决策树的欠拟合风险小，泛化性能往往也要优于预剪枝决策树。但后剪枝过程是在构建**完全决策树**之后进行的，并且要自底向上的对树中的所有非叶结点进行**逐一考察**，因此其**训练时间开销**要比**未剪枝**决策树和**预剪枝**决策树都大得多。

https://blog.csdn.net/u012328159/article/details/79285214