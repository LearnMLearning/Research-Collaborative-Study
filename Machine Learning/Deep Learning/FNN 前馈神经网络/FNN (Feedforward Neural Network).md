前馈神经网络由多层神经元组成，层间的神经元相互连接，层内的神经元不连接。其信息处理机制是:前一层神经元通过层间连接向后一层神经元传递信号，因为信号是从前往后转递的，所以是“前馈的”信息处理网络。这里，神经元是对多个输入信号(实数向量)进行非线性转换产生一个输出信号(实数值)的函数，整个神经网络是对多个输入信号(实数向量)进行多次非线性转换产生多个输出信号 (实数向量)的复合函数。每一个神经元的函数含有参数，神经网络的神经元的参数通过学习得到。当前馈神经网络的层数达到一定数量时(一般大于 2)，又称为深度神经网络(deep neural network，[[DNN]])。
前馈神经网络学习算法是反向传播 (back propagation) 算法，是 随机梯度下降法 的具体实现。学习的损失函数通常在分类时是 交叉熵损失，在回归时是 平方损失，其最小化等价于 极大似然估计。学习的正则化方法包括 早停法(early stopping)、暂退法(dropout)。

## 1 FNN 的模型

神经网络是由神经元连接组成的网络，采用不同类型的神经元以及神经元的不同连接方法可以构建出不同的网络结构，也就是不同的神经网络模型。本节讲述 FNN 的基本模型。首先给出 FNN 的定义，接着介绍具体例子，最后讨论 FNN 的表示能力。

#### 1.1 前馈神经网络定义
###### 1. 神经元
人工神经元 (artificial neuron) 是神经网络的基本单元。
生物神经元一般有多个树突接入，一个轴突接出。输入信号从树突传入，输出信号从轴突传出。当输入信号量达到阈值后，神经元被激活，产生输出信号。

与其对应，人工神经元是以实数向量为输入，实数值为输出的非线性函数，表示多个输入信号 (实数向量) 到一个输出信号 (实数值) 的非线性转换。

**定义**
神经元是如下定义的非线性函数:
$$
y = f(x_1,x_2,\cdots,x_n) = a \left(\sum_{i=1}^n w_i x_i + b \right)
$$
或者写作
$$
y = f(x_1,x_2,\cdots,x_n) = a(z),z = \sum_{i=1}^n w_ix_i + b
$$
其中，$x_1,x_2,\cdots,x_n$ 是输入，取实数值; $y$ 是输出，取实数值； $z$ 是中间结果，又称作净输入 (net input)，也取实数值; $w_1,w_2,\cdots,w_n$ 是权重 (weight), $b$ 是偏置 (bias)，也都取实数值；$z=\sum_{i=1}^n w_i x_i + b$ 是仿射函数; $a(\cdot)$ 是特定的非线性函数，成为激活函数。激活函数有多种形式，比如 $S$ 型函数:
$$
a(z) = \frac{1}{1+e^{-z}}
$$

神经元函数由两部分组成，首先使用仿射函数对输入 $x_1,x_2,\cdots,x_n$ 进行仿射变换，得到净输入 $z$，然后使用激活函数 $a(z)$ 对净输入 $z$ 进行非线性变换，得到输出 $y$。权重 $w_1,w_2,\cdots,w_n$ 与偏置 $b$ 是神经元函数的参数，通过学习得到。

