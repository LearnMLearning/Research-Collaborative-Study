后剪枝就是先构造一颗完整的决策树，然后自底向上的对非叶结点进行考察，若将该结点对应的子树换为叶结点能够带来泛化性能的提升，则把该子树替换为叶结点。前剪枝时已经说过了，使用前面给出的训练集会生成一颗（未剪枝）决策树：
![[Pasted image 20240630145728.png]]
后剪枝算法首先考察上图中的结点 (6)，若将以其为根节点的子树删除，即相当于把结点 (6) 替换为叶结点，替换后的叶结点包括编号为 $\{7,15\}$ 的训练样本，因此把该叶结点标记为“好瓜”（因为这里正负样本数量相等，所以随便标记一个类别），因此此时的决策树在验证集上的精度为 $57.1\%$（为剪枝的决策树为 $42.9\%$ ），所以后剪枝策略决定剪枝，剪枝后的决策树如下图所示：
![[Pasted image 20240630145823.png]]
