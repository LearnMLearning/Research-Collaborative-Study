#### 基本介绍
回归树采用**均方误差**作为损失函数，树生成时会递归的按最优特征与最优特征下的最优取值对空间进行划分，直到满足停止条件为止。

回归树该怎么确定哪个分法才最好呢？最小二乘！经典的最小二乘算法！
之所以称为最小二乘回归树，是因为，回归树以误差平方和为准则选择最优二分切点，该生成算法在训练数据集上所在的输入空间中，递归的将每个区域划分为两个子区域并决定每个子区域的输出值，在这里分为两种情况，一是输出值为子区域输出值的均值该种情况下为回归树，二是输出值为子区域输入与输出的线性回归，输出值为回归系数，该种情况下为模型树。

#### 实现步骤
构建回归树的步骤如下：
**输入：** 训练数据集 $D=\{(x_1,y_1),(x_2,y_2),\dots,(x_N,y_N)\}$
**输出：** 回归树 $T$
(1) 求解选择切分特征 $j$ 与切分特征取值 $s$。$j$ 将训练集 $D$ 划分为两部 $R_1$ 与 $R_2$，依照 $(j,s)$ 切分后如下：
$$
R_1(j,s) = \{x_i | x_i^j \le s\} , R_2 (j,s) = \{x_i | x_i ^j >s\}
$$
$$
c_1 = \frac 1{N_1} \sum_{x_i \in R_1} y_i , c_2 = \frac{1}{N_2} \sum_{x_i \in R_2}y_i
$$
其中，$c_1, c_2$ 分别为左右子区域输出的均值（模型树时是输出变量的回归值），可通过遍历每个变量的每个可能取值来切分数据集找出最优切分点。

(2) 遍历所有可能的解 $(j,s)$，找到最优的 $(j^∗,s^∗)$，最优的解使得对应损失最小，按照最优特征 $(j^∗,s^∗)$ 来切分即可。
$$
\text{min}_{j,s} \left[\sum_{x_i \in R_1} (y_i - c_1)^2 + \sum_{x_i \in R_2} (y_i - c_2 )^2 \right]
$$
(3) 递归条用(1)∼(2)，直到满足停止条件。  
(4) 返回决策树T

注：停止条件可以人为设定，比如说设置某个节点的样本容量小于给定的阈值 c ，或者当切分后的损失减小值小于给定的阈值小于给定的 ε，则停止切分，生成叶节点。
